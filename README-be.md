

# 🎯 소프트웨어 아키텍처
<details>
  <summary><b>레이어드 아키텍처 + 멀티모듈 아키텍처</b></summary>
  
## 레이어드 아키텍처(Layerd Architecture)
  
  > 레이어드 아키텍처는 소프트웨어를 여러 계층으로 나누어 설계하는 방식입니다. 각 레이어는 정해진 역할을 가집니다.

1. 레이어 간의 책임이 명확하게 분리되어 있어 코드 변경 시 영향 범위를 최소화할 수 있습니다.
2. 레이어 간의 의존 흐름이 일정하여 새로운 기능 개발 시 통일된 프로세스로 빠르게 개발할 수 있었습니다.

<br/>

## 멀티모듈 아키텍처(MultyModule Architecture)
  
> 멀티모듈 아키텍처는 여러 개의 작은 단위 모듈로 소프트웨어를 나누어 설계하는 방식입니다. 각 모듈은 독립적으로 개발되고 배포될 수 있으며, 모듈 간 재사용성을 높여 전체 시스템의 복잡성을 효율적으로 관리할 수 있습니다.

1. 공통 모듈을 여러 프로젝트에서 재사용할 수 있어 코드 중복을 줄일 수 있습니다.
2. 각 모듈이 독립적으로 개발되고 배포될 수 있어 개발 및 테스트의 효율성이 향상됩니다.
3. 기존 모듈을 확장하기 쉽기 때문에 전체 시스템의 복잡성을 효율적으로 관리 가능합니다.

### 1. 멀티모듈 아키텍처 도입 배경 
 프로젝트 초기에는 모든 기능이 단일 모듈로 구성되어 있었습니다. 하지만, 기능이 다양해지고 서버의 역할이 분리될 필요가 생기면서, 각각의 책임에 맞게 모듈을 분리해야 했습니다. 따라서, 프로젝트를 Batch, Common, API-Server라는 세 모듈로 나누었습니다.


![image](https://github.com/user-attachments/assets/4a9a9fa4-4c33-42a4-b97a-27d22d961a3a)

 
### 2. 모듈 구성 및 역할
- **Common 모듈** <br/>
  공통적으로 사용되는 코드와 설정을 관리합니다. 주로 데이터베이스 관련 설정, 공통 유틸리티 클래스 등이 포함되어 있습니다.
- **API-Server 모듈** <br/>
  사용자 요청을 처리하고, 실시간 SSE 알람을 제공하는 등 웹 애플리케이션의 중심이 되는 모듈입니다. 스프링 부트 웹 의존성을 가지고 있어 SSE 알람 서비스를 구현할 수 있습니다.
- **Batch 모듈** <br/>
   일정 작업을 주기적으로 실행하는 서버로, 리마인드 알람 작업 등 배치 처리를 담당합니다. 스프링 배치를 사용하여 멀티 스레드 기반으로 작업을 효율적으로 처리하고, 한 번 실행된 후 종료됩니다.

### 3. 주요 이슈 및 해결 방안

> 멀티모듈화를 진행하면서 SSE 알람 서비스의 의존성 문제가 있었습니다. SseEmitter 클래스를 사용하기 위해서는 spring-boot-web 의존성이 필요했으나, 이 의존성은 배치 모듈의 특성과 맞지 않았습니다. 

이 문제를 해결하기 위해 SSE 알람 전송 로직은 API-Server 모듈에 남겨두어 클라이언트와의 실시간 통신을 유지할 수 있도록 했습니다. 또한 모듈 간 결합도를 낮추기 위해 **Kafka를 사용하여 모듈 간 메시지를 전달하는 구조**를 도입했습니다. Batch 모듈에서 알람 메시지를 Kafka를 통해 전달하면, API-Server 모듈이 이를 수신하여 적절한 SSE 알람을 클라이언트에게 보냅니다. 이를 통해 모듈 간 결합도를 낮추고, 새로운 기능이 추가되더라도 서로의 변경에 영향을 덜 받도록 설계할 수 있었습니다.

### 4. 구조 개선의 효과

- **유지보수성 및 확장성 증가** <br/>
  각 모듈이 독립적으로 개발 및 확장할 수 있는 구조로 변경되었습니다.

- **결합도 감소** <br/>
  모듈 간 의존성을 줄여 변경에 유연하게 대응할 수 있었습니다.

- **성능 최적화** <br/>
  Batch 모듈은 멀티 스레드를 활용한 배치 작업으로 리소스 사용을 최적화하고, API-Server 모듈은 실시간 통신을 유지하는 구조로 설계하여 성능을 개선했습니다.

<br/>

## 레이어드 아키텍처 + 멀티모듈 아키텍처
레이어드 아키텍처를 기반으로 API 서버와 공통 모듈로 구성된 멀티 모듈 구조를 채택 함으로써 API 서버는 주요 비즈니스 로직을 담당하고, 공통 모듈은 엔티티와 같은 재사용 가능한 컴포넌트를 관리하여 모듈 간의 중복을 줄이고 코드의 재사용성을 높였습니다.


</details>


<br>

# ✨ 주요 기능
<details>
  <summary><b>검색</b></summary>
  <div markdown="1">

![image](https://github.com/user-attachments/assets/4f08ce80-c1fc-4777-ae44-edef10c648ad)


## 조회 기능 개선: JPQL에서 QueryDSL로의 전환

> 캘린더와 대시보드에서는 스프린트, 태스크, 회의 등 다양한 상황으로 조회가 필요했습니다. 조회 기능을 개선하기 위해 기존 JPQL 코드를 QueryDSL로 리팩토링하여 동적 쿼리를 적용함으로써, 코드의 가독성과 성능을 모두 향상시켰습니다.

### QueryDSL 전환의 장점

1. **동적 쿼리 작성 용이**
    
    QueryDSL은 코드 기반으로 쿼리를 작성하기 때문에, 조건에 따라 유연하게 동적 쿼리를 생성할 수 있습니다. 이를 통해 복잡한 조회 조건을 쉽게 처리할 수 있으며, 코드의 가독성도 높아집니다.
    
2. **컴파일 타임 안전성**
    
    JPQL은 문자열 기반이므로 런타임 오류가 발생할 가능성이 높습니다. 반면, QueryDSL은 Java 코드로 작성되기 때문에, 쿼리 작성 시점에 컴파일 타임에서 오류를 감지할 수 있기 때문에 코드의 안정성을 강화할 수 있습니다.
    
3. **복잡한 조인 처리의 간결화**
    
    QueryDSL은 엔티티 간의 조인이나 서브쿼리를 쉽게 표현할 수 있어, 복잡한 조회 로직을 간결하게 작성할 수 있습니다.
    
4. **N+1 문제 해결**
    
    QueryDSL을 사용하면 **페치 조인(Fetch Join)**을 통해 연관된 엔티티를 한 번의 쿼리로 함께 조회할 수 있습니다. 이를 통해 JPQL에서 자주 발생하는 N+1 문제를 방지하고, 데이터베이스 접근 횟수를 줄여 성능을 더욱 최적화할 수 있습니다.
    

### 성능 개선 사항

- **불필요한 데이터 조회 최소화**
    
    QueryDSL로 리팩토링하면서, 필요한 필드만 선택적으로 조회하도록 최적화했습니다. 이를 통해 데이터 전송량을 줄이고, 데이터베이스의 부하를 줄일 수 있었습니다.
    
- **쿼리 성능 향상 및 N+1 문제 해결**
    
    동적 쿼리를 작성할 때 조건을 유연하게 추가하고, 페치 조인을 사용해 연관된 엔티티를 한 번의 쿼리로 조회하여 N+1 문제를 해결했습니다. 그 결과, 조회 기능의 응답 속도가 크게 향상되었습니다.

  </div>
</details>

<details>
  <summary><b>💬 채팅 시스템 구조 (WebSocket + STOMP + Kafka)</b></summary>
  <div markdown="1">

---

### 1️⃣ WebSocket & STOMP

#### **사용 기술 및 적용 이유**

<img width="951" height="836" alt="스크린샷 2025-11-12 오전 11 28 21" src="https://github.com/user-attachments/assets/04116730-4fd0-4b1b-b0f5-5bc771a849ca" />

**WebSocket**은 클라이언트와 서버 간의 **지속적인 양방향 통신**을 가능하게 해줍니다.  
이를 통해 사용자는 별도의 요청 없이도 실시간으로 메시지를 주고받을 수 있습니다.  

**STOMP(Simple Text Oriented Messaging Protocol)** 은 WebSocket 위에서 동작하는 프로토콜로,  
메시지를 **Topic 기반으로 라우팅**할 수 있습니다.  
각 채팅방은 **Room ID를 Topic ID로 사용**하여, 같은 채팅방에 있는 사용자들만 메시지를 주고받도록 했습니다.

#### **적용 방식**

- 채팅방 구독 경로: `/sub/chat/room/{roomId}`  
- 메시지 발행 경로: `/pub/chat/message`  
- 사용자는 입장 시 해당 roomId를 구독하고, 메시지를 발행하면 동일 Topic 구독자에게 실시간 전달됩니다.

---

### 2️⃣ 메시지 전송 흐름

#### **서버 간 메시지 동기화 구조**

<img width="1307" height="854" alt="스크린샷 2025-11-12 오전 11 29 05" src="https://github.com/user-attachments/assets/2eb04905-1b1d-4e97-a932-50b16bb6d681" />

- 사용자 A가 **서버 1**에 연결되어 메시지를 전송하면,  
  서버 1의 STOMP가 Kafka에 메시지를 **Publish**합니다.  
- Kafka는 해당 메시지를 **브로커에 저장**하고,  
  **서버 2**의 STOMP Consumer가 동일 Topic을 구독 중이라면 메시지를 전달받습니다.  
- 서버 2는 연결된 **사용자 B**에게 실시간으로 메시지를 전달합니다.  

즉, Kafka를 통해 **멀티 서버 간 메시지 동기화와 전달 보장**이 이루어집니다.

---

### 3️⃣ Kafka 기반 아키텍처

#### **토픽 기반 비동기 처리 구조**

프로젝트에서는 Kafka의 Topic을 두 단계로 나누어 **성능과 안정성**을 동시에 확보했습니다.

| 토픽 이름 | 역할 | 주요 동작 |
|------------|--------|-------------|
| **topic1: message.sent** | 실시간 메시지 전송 | 메시지 송신 & DB 저장 |
| **topic2: message.saved** | 저장 이후 후속 작업 | 파일 URL, 읽음 여부 등 조회 |

**구조 요약**
- Chat-Service (Publisher + Consumer): STOMP 통신 및 Kafka 메시지 발행/수신 담당  
- Chat-DB-Service: 별도의 Consumer Group으로 구성, 메시지 **한 번만 저장**  
- 두 개의 Topic으로 비동기 처리 → **실시간성과 안정성 동시 확보**

---

### 4️⃣ 개선 효과

- **STOMP만 사용 시 발생하던 서버 간 세션 동기화 문제 해결**  
- **Kafka를 통한 메시지 재처리 및 장애 복구 가능**  
- **비동기 분리 구조로 성능 및 응답 속도 개선**  
- **실시간성과 데이터 일관성을 모두 보장하는 고가용성 채팅 시스템 완성**

---

  </div>
</details>


<details>
  <summary><b>알림</b></summary>
  <div markdown="1">


## Spring Batch를 통한 알람 기능 개선

> 기존에는 **`@Scheduled`** 어노테이션을 사용한 스케줄링 방식으로 리마인드 알람을 구현했지만, 서버 부하와 메모리 사용량 증가로 인해 안정적인 서비스 제공에 어려움이 있었습니다. 이를 해결하기 위해 Spring Batch를 도입하여 알람 기능을 개선했습니다.

### 배치 적용 후 개선 사항

1. **역할 분리**
    
    Spring Batch의 Job, Step, Chunk 구조를 사용하여 리마인드 알람 기능을 단계별로 구현했습니다. 각 알람 유형(회의, 스프린트, 태스크)에 대해 독립적인 배치 작업을 설정하여 관리함으로써 코드의 책임을 명확히 하고 작업의 독립성을 유지했습니다.
    
    - **ItemReader**: 데이터베이스에서 회의, 스프린트, 태스크의 마감일 기준으로 알람 대상 데이터를 조회합니다.
    - **ItemProcessor**: 데이터를 검증하고 알람 메시지에 필요한 정보를 가공하여, 알람 시점에 맞는 데이터를 설정합니다.
    - **ItemWriter**: 가공된 데이터를 Kafka를 통해 **`reminder-alarm`** 토픽으로 전송하여 알람 메시지를 처리합니다.
2. **부하 분산**
    - 알람 처리 로직을 독립적인 배치 서버로 분리해 메인 서버의 부하를 줄이고, 작업 분산을 통해 안정적인 서비스를 제공했습니다.
    - 배치 서버에서 발생하는 오류가 메인 서버에 미치는 영향을 최소화했습니다.
3. **확장성 강화**
    - Spring Batch는 배치 모듈에서 알람 메시지를 Kafka를 통해 API 서버로 전달하고, API 서버는 클라이언트에게 알람을 전송합니다.
    - 이는 배치 모듈과 실시간 알람 처리(SSE Emitter)의 의존성 문제를 해결하고, 모듈 간 결합도를 낮춰 확장성과 유연성을 높였습니다.
4. **Kubernetes CronJob을 통한 배치 스케줄링**
    - Kubernetes 환경에서 Spring Batch 작업을 주기적으로 실행하기 위해 CronJob을 사용했습니다.
    - CronJob을 통해 배치 작업을 정기적으로 실행하여 특정 시간에 맞춰 알람 기능을 수행했습니다.
  
   <img src="https://github.com/user-attachments/assets/c9c8d171-0eec-4994-8191-61fbcf3b764e" width="800" heigh="400" />


  
### 배치 적용 후 성능 비교

프로메테우스와 그라파나로 모니터링한 결과, 도입 전에는 알람 발생 시 CPU 사용량이 급증했으나, 도입 후에는 API 서버의 CPU 사용량이 감소하고 배치 서버에 부하가 분산되는 것을 확인할 수 있었습니다. 

**[배치 도입 전 테스트 결과]**

![image](https://github.com/user-attachments/assets/5677f68a-c56b-4199-97b9-fb4fce7e5469)

**[배치 도입 후 테스트 결과]**
![image](https://github.com/user-attachments/assets/bb925ba8-b415-4a81-b41c-609c2210672b)

- 분산 처리 환경을 구축한 결과, 배치 작업 중에도 다른 API 요청에 영향을 주지 않고 서버의 안정성을 유지할 수 있었습니다.
- 멀티스레드를 활용해 병렬 처리한 결과 알람 처리 속도를 11% 향상시켜 전반적인 시스템 성능을 최적화했습니다.


  </div>
</details>
<details>
  <summary><b>실시간 문서편집</b></summary>
  <div markdown="1">

## 1. Redis

### 인메모리 데이터베이스
- **Redis**는 디스크 기반의 RDB와 달리 **인메모리**에서 데이터를 처리하여 **훨씬 빠른 성능**을 제공합니다.
- 일반적인 인메모리 DB와 달리 Redis는 **영속성**을 지원하여, 장애 발생 시에도 데이터를 복구할 수 있습니다.

### 회의록 공동작성 기능에 Redis 적용 이유
- **빠른 읽기 작업**이 중요한 실시간 공동 작성 환경에 적합해서 선택하였습니다.

### Lookaside 캐시 패턴
- **캐시에서 먼저 데이터를 조회**하고, 데이터가 없을 경우 DB에서 조회하여 캐시에 저장하는 방식입니다.
- 반복적인 읽기 작업에서 **성능 향상**을 기대할 수 있으며, **DB 조회 빈도**를 줄여, 캐시를 활용한 효율적인 읽기 작업이 가능합니다.

## 2. Kafka

### 세션 관리 기능
- 서버를 2대 운영하는 환경에서 **Kafka**를 활용하여 세션 관리 기능을 구현하였습니다.
- 클라이언트 간의 원활한 통신을 위해 Kafka를 선택하였으며, **Pub-Sub 모델**을 기반으로 클라이언트 간에 메시지를 주고받습니다.

### Kafka의 장점
- 동일한 **토픽을 구독한 클라이언트들**에게 메시지를 전송하여, **메시지의 일관성**과 **신뢰성**을 보장합니다.
- **서버 간 세션 연결**를 유지할 수 있습니다.

## 3. 시스템 구성도

- **서버 간 세션 연결** 을 위해 kafka 를 활용해 클라이언트간의 연결을 유지시켰습니다.
- **성능 최적화** 를 위해 **LookaSide 패턴**을 적용하여 읽기 작업의 효율성을 높였습니다.

<img width="877" alt="스크린샷 2024-10-24 오후 9 34 26" src="https://github.com/user-attachments/assets/e4ad109f-fae3-47a1-8bdb-fa8ae98f4986">

## 4. REDIS 적용 후 성능 개선

**[REDIS 도입 전 테스트 결과]**

![성능개선전](https://github.com/user-attachments/assets/5cf1459a-61b7-4a71-a7fd-81f7599328d4)

- REDIS 를 도입하기 전 사용자가 작성할 때마다 DB에 업데이트가 되어 성능에 문제가 발생하였습니다.

**[REDIS 도입 후 테스트 결과]**

![성능개선후](https://github.com/user-attachments/assets/2478e3bc-3829-4681-9659-63cfb597c918)

- REDIS 를 도입해 평균 응답 시간이 총 65% 감소했으며, DB 성능 저하 문제도 해결하였습니다.




  </div>
</details>

<details>
  <summary><b>🤖 챗봇 시스템 (N8N + Redis-Semantic)</b></summary>
  <div markdown="1">

---

## 🧭 개요

**우리 시스템의 핵심은 ‘챗봇 중심의 지능형 업무지원 환경’입니다.**  
단순히 일정을 등록하고 조회하는 기존 방식이 아니라,  
대화를 통해 프로젝트 요약, 일정 브리핑, 채팅 요약, 일정 등록 등을 **한 번에 처리할 수 있는 비서형 구조**로 설계했습니다.  

또한 단순 Q&A가 아닌, **서버 내부 기능과 유기적으로 연결된 구조**로 작동합니다.  
예를 들어, 사용자의 질문이 들어오면 n8n 워크플로우가 작동하여  
의도를 분석하고, 필요한 데이터를 서버에서 직접 조회해 응답을 생성합니다.  

---

## ⚙️ N8N? 🤔

![작성 워크플로우](https://github.com/user-attachments/assets/d26cfe96-38d0-4952-aed9-6b503e55ac9a)

**n8n**은 오픈소스 자동화 툴로, 다양한 서비스 간의 연결과  
데이터 흐름을 **시각적 워크플로우**로 구성할 수 있는 플랫폼입니다.  
우리 시스템에서는 **AI 기반 의도 분석, 데이터 처리, 서버 통신**을 모두 n8n에서 자동화했습니다.  

n8n을 활용한 이유는 다음과 같습니다:
- LLM 요청 및 데이터 응답 흐름을 **시각적으로 관리 가능**
- 조건 분기(Switch), HTTP 요청, 함수 실행 등 **세밀한 제어 가능**
- 서버와 AI 에이전트 간 통신을 단일 파이프라인으로 **표준화**

<img width="981" height="773" alt="n8n-workflow" src="https://github.com/user-attachments/assets/636797df-1fd1-49c4-975a-7b75f7c1e4f6" />


---

## 🧩 챗봇 워크플로우 구조
<img width="964" height="564" alt="n8n" src="https://github.com/user-attachments/assets/e1264678-e968-4044-9723-cb48622d5587" />

n8n 내부에서 챗봇은 다음과 같은 흐름으로 동작합니다:

1. **사용자 요청 수신**  
   서버에서 n8n으로 요청이 들어오면 Webhook을 통해 워크플로우가 시작됩니다.
2. **의도 분석 (LLM)**  
   사용자의 자연어 요청을 분석해 “요약 요청인지”, “일정 조회인지” 등을 분류합니다.  
3. **분기 처리**  
   Switch 노드를 통해 각 의도에 맞는 LLM 또는 API 호출로 분기합니다.
4. **데이터 조회 및 응답 생성**  
   필요한 경우 서버 API를 호출하여 실시간 데이터를 가져오고,  
   LLM이 이를 요약하거나 정리해 최종 응답을 생성합니다.
5. **결과 반환**  
   생성된 결과는 다시 서버로 전송되어 사용자의 대화창에 표시됩니다.

이 구조를 통해 챗봇은 단순 응답을 넘어,  
**실시간 데이터 기반의 ‘지능형 업무 비서’ 역할**을 수행합니다.

---

## 🧠 Redis-Semantic: 의미 기반 캐싱 시스템
<img width="932" height="436" alt="시멘틱1" src="https://github.com/user-attachments/assets/e10884cd-590c-4497-81d7-9d50580229eb" />
<img width="1199" height="539" alt="시멘틱2" src="https://github.com/user-attachments/assets/467f9ded-c114-425c-b9da-83819451b4fb" />

챗봇의 지능형 응답을 가능하게 하는 또 하나의 핵심이 바로  
**Redis Stack 기반 시멘틱 메모리 구조**입니다.

### 작동 원리
1. 사용자의 질문을 OpenAI **임베딩 모델**로 변환 → 의미 벡터 생성  
2. 이 벡터를 **Redis Vector Space**에 저장  
3. 새로운 질문이 들어올 때마다 기존 벡터들과 **유사도 검색 (KNN)** 수행  
4. **90% 이상 유사한 벡터**가 존재하면 LLM 호출 없이 **저장된 응답 즉시 반환**  
5. 유사도가 낮을 경우 LLM을 호출하고, 새 결과를 Redis에 다시 저장

### 효과
- **응답 속도 향상:** 유사 질의는 캐시된 응답을 즉시 반환  
- **비용 절감:** OpenAI API 호출 횟수를 대폭 감소  
- **지속 학습:** Redis가 점차 “지식 저장소”로 확장  

---

## 💡 요약

| 구성 요소 | 역할 | 특징 |
|------------|------|------|
| **N8N Agent** | 챗봇 의도 분석 및 응답 생성 자동화 | LLM 기반 분기 처리 |
| **Redis-Semantic** | 의미 기반 질의 캐싱 | 유사 질문 즉시 응답 |
| **LLM 모듈** | 요약 / 일정 / 채팅 / 일반 응답 처리 | OpenAI 모델 연동 |
| **서버 연동** | 데이터 조회 및 결과 반환 | REST API 통신 |

---

## 🚀 결론

이 구조를 통해 챗봇은 단순 대화형 UI를 넘어,  
**AI와 데이터가 유기적으로 통합된 스마트 업무 파이프라인**으로 진화했습니다.  
n8n의 자동화와 Redis-Semantic의 의미 기반 캐싱을 결합함으로써  
빠르고 정확하며 비용 효율적인 지능형 챗봇을 완성할 수 있었습니다.

---

  </div>
</details>




