

# 🎯 소프트웨어 아키텍처
<details>
  <summary><b>레이어드 아키텍처 + 멀티모듈 아키텍처</b></summary>
  
## 레이어드 아키텍처(Layerd Architecture)
  
  > 레이어드 아키텍처는 소프트웨어를 여러 계층으로 나누어 설계하는 방식입니다. 각 레이어는 정해진 역할을 가집니다.

1. 레이어 간의 책임이 명확하게 분리되어 있어 코드 변경 시 영향 범위를 최소화할 수 있습니다.
2. 레이어 간의 의존 흐름이 일정하여 새로운 기능 개발 시 통일된 프로세스로 빠르게 개발할 수 있었습니다.

<br/>

## 멀티모듈 아키텍처(MultyModule Architecture)
  
> 멀티모듈 아키텍처는 여러 개의 작은 단위 모듈로 소프트웨어를 나누어 설계하는 방식입니다. 각 모듈은 독립적으로 개발되고 배포될 수 있으며, 모듈 간 재사용성을 높여 전체 시스템의 복잡성을 효율적으로 관리할 수 있습니다.

1. 공통 모듈을 여러 프로젝트에서 재사용할 수 있어 코드 중복을 줄일 수 있습니다.
2. 각 모듈이 독립적으로 개발되고 배포될 수 있어 개발 및 테스트의 효율성이 향상됩니다.
3. 기존 모듈을 확장하기 쉽기 때문에 전체 시스템의 복잡성을 효율적으로 관리 가능합니다.

### 1. 멀티모듈 아키텍처 도입 배경 
 프로젝트 초기에는 모든 기능이 단일 모듈로 구성되어 있었습니다. 하지만, 기능이 다양해지고 서버의 역할이 분리될 필요가 생기면서, 각각의 책임에 맞게 모듈을 분리해야 했습니다. 따라서, 프로젝트를 Batch, Common, API-Server라는 세 모듈로 나누었습니다.


![image](https://github.com/user-attachments/assets/4a9a9fa4-4c33-42a4-b97a-27d22d961a3a)

 
### 2. 모듈 구성 및 역할
- **Common 모듈** <br/>
  공통적으로 사용되는 코드와 설정을 관리합니다. 주로 데이터베이스 관련 설정, 공통 유틸리티 클래스 등이 포함되어 있습니다.
- **API-Server 모듈** <br/>
  사용자 요청을 처리하고, 실시간 SSE 알람을 제공하는 등 웹 애플리케이션의 중심이 되는 모듈입니다. 스프링 부트 웹 의존성을 가지고 있어 SSE 알람 서비스를 구현할 수 있습니다.
- **Batch 모듈** <br/>
   일정 작업을 주기적으로 실행하는 서버로, 리마인드 알람 작업 등 배치 처리를 담당합니다. 스프링 배치를 사용하여 멀티 스레드 기반으로 작업을 효율적으로 처리하고, 한 번 실행된 후 종료됩니다.

### 3. 주요 이슈 및 해결 방안

> 멀티모듈화를 진행하면서 SSE 알람 서비스의 의존성 문제가 있었습니다. SseEmitter 클래스를 사용하기 위해서는 spring-boot-web 의존성이 필요했으나, 이 의존성은 배치 모듈의 특성과 맞지 않았습니다. 

이 문제를 해결하기 위해 SSE 알람 전송 로직은 API-Server 모듈에 남겨두어 클라이언트와의 실시간 통신을 유지할 수 있도록 했습니다. 또한 모듈 간 결합도를 낮추기 위해 **Kafka를 사용하여 모듈 간 메시지를 전달하는 구조**를 도입했습니다. Batch 모듈에서 알람 메시지를 Kafka를 통해 전달하면, API-Server 모듈이 이를 수신하여 적절한 SSE 알람을 클라이언트에게 보냅니다. 이를 통해 모듈 간 결합도를 낮추고, 새로운 기능이 추가되더라도 서로의 변경에 영향을 덜 받도록 설계할 수 있었습니다.

### 4. 구조 개선의 효과

- **유지보수성 및 확장성 증가** <br/>
  각 모듈이 독립적으로 개발 및 확장할 수 있는 구조로 변경되었습니다.

- **결합도 감소** <br/>
  모듈 간 의존성을 줄여 변경에 유연하게 대응할 수 있었습니다.

- **성능 최적화** <br/>
  Batch 모듈은 멀티 스레드를 활용한 배치 작업으로 리소스 사용을 최적화하고, API-Server 모듈은 실시간 통신을 유지하는 구조로 설계하여 성능을 개선했습니다.

<br/>

## 레이어드 아키텍처 + 멀티모듈 아키텍처
레이어드 아키텍처를 기반으로 API 서버와 공통 모듈로 구성된 멀티 모듈 구조를 채택 함으로써 API 서버는 주요 비즈니스 로직을 담당하고, 공통 모듈은 엔티티와 같은 재사용 가능한 컴포넌트를 관리하여 모듈 간의 중복을 줄이고 코드의 재사용성을 높였습니다.


</details>


<br>

# ✨ 주요 기능
<details>
  <summary><b>🔍 검색(elasticsearch + kafka + nori, Edge N-gram)</b></summary>
  <div markdown="1">

---
  ### 1️⃣ 비동기 검색 아키텍처 (Kafka + Elasticsearch)

#### **문제: 원본 서비스의 성능 저하 및 장애 전파**

검색 기능을 구현할 때, 원본 서비스(문서, 파일 등)가 데이터 변경 시마다 Elasticsearch에 직접 동기식으로 인덱싱을 요청하면 2가지 큰 문제가 발생합니다.

1.  **성능 저하 (응답 속도):** Elasticsearch의 색인 작업은 비용이 큰 작업입니다. 원본 서비스는 이 작업이 끝날 때까지 기다려야 하므로, 사용자의 CUD(생성, 수정, 삭제) 요청에 대한 응답 속도가 치명적으로 느려집니다.
2.  **장애 전파 (결합성):** 검색 시스템이나 Elasticsearch에 일시적인 장애가 발생하면, 인덱싱 API 호출이 실패하게 됩니다. 이 장애가 원본 서비스에까지 전파되어, 데이터 저장 로직 전체가 실패할 수 있습니다.

#### **해결: Kafka를 이용한 비동기식 인덱싱 파이프라인**

이 문제를 해결하기 위해 Kafka를 중간 버퍼로 두는 비동기 아키텍처를 구축했습니다.

1.  **이벤트 발행 (Produce):** 원본 서비스(문서, 파일, 스톤)에서 CUD가 발생하면, Kafka에 '데이터 변경 이벤트'를 발행(Produce)하고 즉시 응답을 반환합니다.
2.  **이벤트 구독 (Consume):** 별도의 검색 시스템(Consumer)이 해당 토픽을 구독(Subscribe)하고 있습니다.
3.  **비동기 인덱싱:** 검색 시스템은 이벤트를 전달받아 비동기적으로 Elasticsearch의 인덱스를 갱신합니다.

**개선 효과:**
* **성능:** 원본 서비스는 Kafka에 메시지만 전달하면 되므로, Elasticsearch의 색인 작업을 기다릴 필요 없이 **빠른 응답 속도**를 유지할 수 있습니다.
* **안정성:** 검색 시스템이나 Elasticsearch에 장애가 발생하더라도, Kafka가 이벤트를 안전하게 보관(Retention)해주기 때문에 **데이터 유실 없는 안정적인 동기화**가 가능합니다.

---

### 2️⃣ 핵심 검색 기능: 자동완성 vs. 통합 검색

검색 서비스는 사용자의 의도에 따라 '자동완성'과 '통합 검색'이라는 두 가지 핵심 기능을 제공합니다.

| 기능 | 설명 | 검색 대상 (Analyzer) | 주요 쿼리 (Elasticsearch) |
| :--- | :--- | :--- | :--- |
| **🚀 자동완성** | 키워드를 입력하는 '중간'에 실시간으로 검색어를 '제안' | **제목** (n-gram) | `match_bool_prefix` |
| **🔍 통합 검색** | 'Enter' 키를 눌러 실행하는 완전한 '검색' | **제목** (n-gram) + **본문** (nori) | `bool`, `multi_match`, `inner_hits` |

#### **상세 구현: 자동완성 (Autocomplete)**
* 사용자의 키 입력마다 실시간으로 호출되어야 하므로 **속도**가 가장 중요합니다.
* `match_bool_prefix` 쿼리를 사용하여 매우 빠른 속도로 '입력 중인' 단어를 제안합니다.
* 빠른 조회를 위해 검색 대상을 **제목**으로 한정하고 최소한의 정보만 반환하도록 설계했습니다.

#### **상세 구현: 통합 검색 (Full Search)**
* 제목과 본문 전체를 대상으로 검색하며, **정확도**와 **결과 품질**이 중요합니다.
* 본문 내용은 `nori` 형태소 분석기를 사용하여 한국어의 의미를 분석, 더 정확한 검색이 가능합니다.
* 검색 결과에 키워드와 일치하는 부분을 **하이라이팅(Highlighting)** 처리하고, 주변 100글자 이내의 내용을 함께 조회하여 맥락을 파악하기 쉽도록 했습니다.
* **검색 결과 라우팅:**
    * 스톤/테스크: 해당 스톤의 위치(링크)로 이동
    * 파일/문서: 직접 열기 + 원본 문서함 링크 제공

---

### 3️⃣ 기술 결정: 왜 Spring Data JPA 대신 NativeQuery를 사용했는가?

Spring Data Elasticsearch(JPA 방식)는 편리하지만, 복잡한 검색 요구사항을 충족하는 데 한계가 있었습니다. 따라서 Elasticsearch의 모든 기능을 활용하기 위해 **NativeQuery(High-Level Rest Client)** 방식을 채택했습니다.

1.  **✔️ 하이라이팅(Highlighting) 적용:**
    * JPA 방식으로는 검색 키워드 하이라이팅 같은 부가적인 옵션을 적용하기 매우 까다롭습니다. NativeQuery는 JSON 기반으로 옵션을 직접 제어할 수 있어 적용이 쉽습니다.

2.  **✔️ 복잡한 쿼리 조합:**
    * "제목은 부분 일치(`n-gram`), 본문은 구문 일치(`nori`), 문서 라인(중첩 객체)은 `inner_hits`로 검색"과 같은 복잡한 `bool` 쿼리 조합이 필요했습니다. NativeQuery는 이를 유연하게 구현할 수 있습니다.

3.  **✔️ 성능 최적화 쿼리 활용:**
    * 자동완성을 위한 `match_bool_prefix` 쿼리는 JPA에서 공식 지원하지 않는 ES 고유의 고성능 쿼리입니다.

4.  **✔️ 다중 인덱스 오류 제어:**
    * 파일, 문서, 스톤 등 **서로 다른 매핑(구조)**을 가진 인덱스들을 동시에 검색해야 했습니다.
    * 문서(Document) 인덱스에만 존재하는 '라인(Lines)' 필드를 다른 인덱스에서 검색 시도 시 오류가 발생합니다.
    * NativeQuery의 `.ignoreUnmapped(true)` 옵션을 통해 이 문제를 간단히 해결했습니다.

5.  **✔️ 반환 필드 동적 제어:**
    * NativeQuery는 반환받을 필드(`_source`)를 동적으로 제어하기 유리하여, 불필요한 데이터 전송을 줄여 성능을 최적화할 수 있습니다.

---

### 4️⃣ 트러블슈팅: 이종(異種) 데이터 본문 추출 및 검색

검색 대상(파일, 문서, 스톤)들은 각기 다른 데이터 구조와 본문 저장 방식을 가집니다.

#### **문제 1: 파일(PDF, DOCX) 및 HTML 문서의 본문은 어떻게 검색하는가?**
* 파일은 바이너리 형태이고, 문서는 HTML 태그가 포함되어 있어 그대로는 텍스트 검색이 불가능했습니다.

#### **해결 1: 라이브러리를 통한 본문 텍스트 추출**
인덱싱 파이프라인에서 라이브러리를 활용해 순수 텍스트만 추출하여 저장했습니다.

| 대상 | 사용 라이브러리 | 적용 시점 및 방식 |
| :--- | :--- | :--- |
| **파일 (PDF, DOCX 등)** | **Apache Tika** | 파일 업로드 시점에 Tika가 파일 본문 내용을 추출하여 Kafka 이벤트에 포함시킴 |
| **문서 (HTML 기반)** | **Jsoup** | 검색 시스템(Consumer)이 Kafka 메시지 수신 시, Jsoup으로 HTML 태그를 모두 제거하고 순수 텍스트만 추출하여 인덱싱 |

#### **문제 2: 문서(1:N)와 나머지(1:1)의 다른 구조를 어떻게 동시에 검색하는가?**
* 파일, 스톤 등은 `[객체 1 : 본문 1]` 구조입니다.
* 문서는 협업 편집기 특성상 `[문서 1 : 라인 N]` 구조로, 실제 본문이 여러 개의 `Line` 중첩 객체에 나뉘어 저장됩니다.

#### **해결 2: Inner Hits를 사용한 중첩 객체 검색**
* 문서 타입에 대해서는 `inner_hits` 쿼리를 사용하여, 문서 전체가 아닌 **"키워드와 매칭된 특정 라인"**을 정확히 찾아 반환하도록 구현했습니다.
* 앞서 3번에서 언급한 `ignoreUnmapped` 옵션 덕분에, '라인(Lines)' 필드가 없는 파일/스톤 인덱스에서도 이 복합 쿼리가 오류 없이 동작합니다.
  
</details>

<details>
  <summary><b>💬 채팅 시스템 구조 (WebSocket + STOMP + Kafka)</b></summary>
  <div markdown="1">

---

### 1️⃣ WebSocket & STOMP

#### **사용 기술 및 적용 이유**

<img width="951" height="836" alt="스크린샷 2025-11-12 오전 11 28 21" src="https://github.com/user-attachments/assets/04116730-4fd0-4b1b-b0f5-5bc771a849ca" />

**WebSocket**은 클라이언트와 서버 간의 **지속적인 양방향 통신**을 가능하게 해줍니다.  
이를 통해 사용자는 별도의 요청 없이도 실시간으로 메시지를 주고받을 수 있습니다.  

**STOMP(Simple Text Oriented Messaging Protocol)** 은 WebSocket 위에서 동작하는 프로토콜로,  
메시지를 **Topic 기반으로 라우팅**할 수 있습니다.  
각 채팅방은 **Room ID를 Topic ID로 사용**하여, 같은 채팅방에 있는 사용자들만 메시지를 주고받도록 했습니다.

#### **적용 방식**

- 채팅방 구독 경로: `/sub/chat/room/{roomId}`  
- 메시지 발행 경로: `/pub/chat/message`  
- 사용자는 입장 시 해당 roomId를 구독하고, 메시지를 발행하면 동일 Topic 구독자에게 실시간 전달됩니다.

---

### 2️⃣ 메시지 전송 흐름

#### **서버 간 메시지 동기화 구조**

<img width="1307" height="854" alt="스크린샷 2025-11-12 오전 11 29 05" src="https://github.com/user-attachments/assets/2eb04905-1b1d-4e97-a932-50b16bb6d681" />

- 사용자 A가 **서버 1**에 연결되어 메시지를 전송하면,  
  서버 1의 STOMP가 Kafka에 메시지를 **Publish**합니다.  
- Kafka는 해당 메시지를 **브로커에 저장**하고,  
  **서버 2**의 STOMP Consumer가 동일 Topic을 구독 중이라면 메시지를 전달받습니다.  
- 서버 2는 연결된 **사용자 B**에게 실시간으로 메시지를 전달합니다.  

즉, Kafka를 통해 **멀티 서버 간 메시지 동기화와 전달 보장**이 이루어집니다.

---

### 3️⃣ Kafka 기반 아키텍처

#### **토픽 기반 비동기 처리 구조**

프로젝트에서는 Kafka의 Topic을 두 단계로 나누어 **성능과 안정성**을 동시에 확보했습니다.

| 토픽 이름 | 역할 | 주요 동작 |
|------------|--------|-------------|
| **topic1: message.sent** | 실시간 메시지 전송 | 메시지 송신 & DB 저장 |
| **topic2: message.saved** | 저장 이후 후속 작업 | 파일 URL, 읽음 여부 등 조회 |

**구조 요약**
- Chat-Service (Publisher + Consumer): STOMP 통신 및 Kafka 메시지 발행/수신 담당  
- Chat-DB-Service: 별도의 Consumer Group으로 구성, 메시지 **한 번만 저장**  
- 두 개의 Topic으로 비동기 처리 → **실시간성과 안정성 동시 확보**

---

### 4️⃣ 개선 효과

- **STOMP만 사용 시 발생하던 서버 간 세션 동기화 문제 해결**  
- **Kafka를 통한 메시지 재처리 및 장애 복구 가능**  
- **비동기 분리 구조로 성능 및 응답 속도 개선**  
- **실시간성과 데이터 일관성을 모두 보장하는 고가용성 채팅 시스템 완성**

---

  </div>
</details>

<details>
  <summary><b>🔔 알림 시스템 (Kafka + Redis Pub/Sub + Redis ZSET)</b></summary>
  <div markdown="1">

---

## 🧭 개요

<img width="1048" height="899" alt="알림1" src="https://github.com/user-attachments/assets/a8ea7210-a67c-4de4-bf16-375b300eedd9" />


우리의 **알림 시스템**은 **Kafka와 Redis**를 결합한 **하이브리드 구조**로 설계되었습니다.  
여러 서비스 서버에서 발생하는 알림 이벤트를 **Kafka**를 통해 안정적으로 수집하고,  
이를 **Noti Service**가 구독하여 **Redis Pub/Sub**으로 실시간 전파함으로써  
**확장성과 실시간성**을 모두 확보했습니다.  

이 구조는 단순한 브로드캐스트를 넘어,  
알림 데이터의 **저장, 재처리, 예약 발송까지** 모두 한 흐름 안에서 관리합니다.

---

## ⚙️ 전체 구조

1. **다양한 서비스에서 알림 이벤트 발생**
   - `chat-service`, `workspace-service`, `calendar-service`, `document-service` 등  
     여러 마이크로서비스에서 Kafka로 알림 메시지를 발행(publish)
2. **Kafka를 통한 안정적 메시지 전달**
   - Kafka는 메시지를 브로커에 저장하며,  
     **DB 저장 + Redis 전파를 하나의 메시지 단위로 관리**
3. **Noti Service에서 구독 및 처리**
   - Consumer 그룹 내 Noti Service가 메시지를 구독하고  
     DB에 저장한 뒤 Redis Pub/Sub으로 실시간 전송
4. **Redis Pub/Sub으로 프론트 실시간 전달**
   - WebSocket 구독 중인 프론트엔드 클라이언트로 즉시 전파
5. **Redis Z-Set을 통한 예약 알림 처리**
   - 예약 알림은 시간 기반 score로 저장되어  
     스케줄러가 1초마다 현재 시간에 해당하는 알림만 빠르게 조회 및 발행

---

## ⚡ 실시간 알림 처리

Kafka → Noti Service → Redis Pub/Sub → Frontend

- Redis Pub/Sub을 통해 알림이 즉시 전송되며,  
  여러 서버 환경에서도 하나의 이벤트가 **일관되게 브로드캐스트**됩니다.
- 메모리 기반 처리이기 때문에  
  **지연이 거의 없고, 트래픽이 많아도 부하가 낮습니다.**

---

## 🕒 예약 알림 처리 (Redis Z-Set)

- 예약 알림은 Redis의 **Z-Set**에 저장되어  
  “시간”을 score로 사용해 자동 정렬됩니다.
- Noti Service 내 Scheduler가  
  1초마다 현재 시각에 해당하는 알림만 조회 및 전송합니다.
- RDB 기반 쿼리보다 훨씬 가볍고,  
  서버 부하가 적으며 빠른 조회가 가능합니다.

---

## 💡 핵심 장점 요약

| 구성 요소 | 역할 | 특징 |
|------------|------|------|
| **Kafka** | 메시지 저장 및 전달 | 장애 내구성, 재처리 가능 |
| **Redis Pub/Sub** | 즉시 알림 전파 | 저지연, 가벼운 브로드캐스트 |
| **Redis Z-Set** | 예약 알림 관리 | 시간 기반 정렬, 빠른 조회 |
| **하이브리드 구조** | 안정성 + 실시간성 통합 | Kafka의 복구력 + Redis의 속도 |

---

## 🎯 정리

- Kafka로 **메시지의 일관성과 복구 가능성** 확보  
- Redis Pub/Sub으로 **가볍고 빠른 실시간 전파** 구현  
- Redis Z-Set으로 **예약 알림을 효율적으로 관리**  
- 최종적으로 Kafka의 **안정성**과 Redis의 **실시간성**을 결합한  
  **확장성과 신뢰성을 모두 갖춘 알림 시스템**을 완성했습니다.

---

  </div>
</details>


<details>
  <summary><b>📝 실시간 문서편집(redis Hash/Set + redis pub/sub + WebSocket/Stomp)</b></summary>
  <div markdown="1">

---
    
### **1️⃣ 실시간 동시 편집 아키텍처**

#### **문제: "문서 전체" 저장 방식의 3중 문제**

초기 설계는 `Document` 엔티티의 단일 `content` 컬럼에 문서 내용 전체를 저장했습니다. 이 방식은 3가지 치명적인 문제를 동시에 유발했습니다.

1.  **동시성 충돌 (Lost Update):**
    * 사용자 A와 B가 동시에 수정 시, 나중에 저장한 B의 내용이 A의 수정을 덮어씁니다.
    * **낙관적 락(Optimistic Lock)의 한계:** 락의 목적이 "거부(Reject)"이므로, 여러 변경 사항을 "병합(Merge)"해야 하는 협업 편집기에 부적합했습니다.

2.  **DB 부하 (Full Overwrite):**
    * 단 한 글자만 수정해도 수 MB에 달하는 문서 전체를 `UPDATE` 해야 했습니다.
    * 이는 극심한 DB 부하와 Lock 경합을 유발했습니다.

3.  **STOMP 메시지 크기 제한:**
    * 변경 사항 전파를 위해 문서 전체를 STOMP 메시지로 전송 시, WebSocket의 프레임 크기 제한(기본 64KB)을 초과하여 전송 자체가 실패했습니다.

#### **해결: "라인 단위" 연결 리스트(Linked List) 구조**

문제를 근본적으로 해결하기 위해 아키텍처를 전면 재설계했습니다.

-   문서를 "라인(Line) 단위"로 분리하여 `DocumentLine` 엔티티에 개별 저장합니다.
-   `prevId` (이전 라인의 ID)를 통해 각 라인의 순서를 관리하는 **연결 리스트 구조**를 채택했습니다.
-   **핵심 개선점:**
    * **(부하 해결)** 변경된 라인만 `UPDATE` 하므로 DB 부하가 최소화되었습니다.
    * **(메시징 해결)** 변경된 라인의 JSON 데이터(수십 바이트)만 STOMP로 전송하므로 크기 제한 문제를 완벽히 회피했습니다.
    * **(동시성 해결)** 라인 단위로 잠금을 적용할 수 있는 기반을 마련했습니다. (아래 2번 항목)

---

### 2️⃣ Redis 분산 락 기반 동시성 제어

#### **문제: 👻 "유령 잠금 (Stale Lock)" 및 동시 수정**

라인 단위로 구조를 변경했음에도, 동시성 문제는 여전히 남아있었습니다.

-   **동시 수정:** 여러 사용자가 같은 라인을 동시에 수정할 때 데이터가 덮어써지는 문제를 막아야 했습니다.
-   **유령 잠금:** 사용자가 라인을 잠근 상태에서 네트워크가 끊기거나 브라우저를 강제 종료하면, 서버는 `unlock` 이벤트를 받지 못해 해당 라인이 **영원히 잠기는** 문제가 발생했습니다.

#### **해결: WebSocket Disconnect 연계 자동 잠금 해제**

Redis의 Hash와 Set을 활용하고 WebSocket의 생명주기와 연동하여 문제를 해결했습니다.

1.  **라인 잠금 (HSETNX):**
    * 사용자가 라인 편집 시작 시, Redis Hash `lock:{documentId}`에 `HSETNX` (Hash-Set-if-Not-Exists) 명령으로 `lineId`를 Key로 하여 자신의 `userId`를 저장, 원자적으로 잠금을 획득합니다.
2.  **사용자별 잠금 추적 (SADD):**
    * 동시에, `user_lock:{documentId}:{userId}` (Redis Set)에 내가 잠근 `lineId`를 `SADD`로 저장합니다.
3.  **비정상 종료 감지 (Disconnect Listener):**
    * Spring에서 WebSocket의 `Disconnect` 이벤트를 감지합니다.
4.  **유령 잠금 일괄 해제 (SMEMBERS + HDEL):**
    * 연결이 끊어진 `userId`를 기반으로 `user_lock` Set을 `SMEMBERS`로 조회하여, 해당 유저가 잠갔던 모든 `lineId` 리스트를 가져옵니다.
    * 메인 `lock` Hash에서 `HDEL` 명령으로 이 라인들을 모두 일괄 삭제합니다.
    * 마지막으로 `user_lock` Set 자체도 삭제합니다.

**결과:** 사용자가 비정상 종료되어도, 해당 사용자가 점유했던 모든 잠금이 1~2초 내(연결 타임아웃 감지 후)에 자동으로 해제되어 안정적인 협업이 가능합니다.

---

### 3️⃣ 데이터 정합성 및 부하 제어

실시간성과 시스템 안정성 사이의 타협점을 찾기 위해 여러 문제를 추가로 해결했습니다.

| 문제 상황 | 핵심 원인 | 해결 방안 (Solution) |
| :--- | :--- | :--- |
| **🌪️ 메시지 스톰 (Message Storm)**<br/>**(RDB 커넥션 고갈)** | '가나다' 입력 시 'ㄱ', '가', '간' 등 모든 키 입력(Keystroke)마다 이벤트가 폭풍처럼 전송되어 DB 커넥션 풀 고갈 | **클라이언트 (Debouncing):** 150ms~300ms간 입력을 모아 단일 요청.<br/>**서버 (Batch Update):** `changesList` DTO로 여러 변경을 단일 트랜잭션으로 처리. (RDB 부하를 N배에서 1로 줄임) |
| **💾 DB vs 실시간 정합성 불일치** | Redis Pub/Sub 전파는 성공했으나(실시간), DB 트랜잭션이 **Rollback**되어 데이터가 불일치하는 상황 (새로고침 시 롤백됨) | **트랜잭션 순서 보장:** `@Transactional` 내에서 DB 저장 로직을 **먼저** 수행.<br/>**DB Commit 성공 이후**에만 Redis Pub/Sub 메시지를 발행하여 정합성 확보. |
| **📣 메아리(Echo) 및 순서 꼬임** | 내가 보낸 메시지를 내가 다시 수신하여 중복 표시됨 (Echo).<br/>네트워크 지연으로 메시지 순서가 섞임. | **메아리:** `senderId`를 DTO에 포함. 클라이언트는 `senderId == selfId`인 메시지 무시.<br/>**순서 보장:** `lineId`와 `prevId` (연결 리스트) 기준으로 클라이언트가 재조립. |

---

### 4️⃣ 개선 효과

-   **"문서 전체" 저장 방식의 동시성, DB 부하, 메시지 크기 3중 문제 동시 해결**
-   **라인 단위 Redis 분산 락을 적용하여 안정적인 동시 편집 환경 구현**
-   **비정상 종료 시 "유령 잠금(Stale Lock)"을 자동으로 해제하여 편집 불능 상태 방지**
-   **Debouncing 및 Batch Update로 RDB 커넥션 고갈 및 "메시지 스톰" 부하 해결**
-   **DB Commit 우선 순서 보장으로 실시간 데이터와 DB 데이터 간의 정합성 확보**
-   **연결 리스트(`prevId`) 구조를 통해 메시지 순서가 섞여도 일관된 문서 상태 유지**
</details>

<details>
  <summary><b>🤖 챗봇 시스템 (N8N + Redis-Semantic)</b></summary>
  <div markdown="1">

---

## 🧭 개요

**우리 시스템의 핵심은 ‘챗봇 중심의 지능형 업무지원 환경’입니다.**  
단순히 일정을 등록하고 조회하는 기존 방식이 아니라,  
대화를 통해 프로젝트 요약, 일정 브리핑, 채팅 요약, 일정 등록 등을 **한 번에 처리할 수 있는 비서형 구조**로 설계했습니다.  

또한 단순 Q&A가 아닌, **서버 내부 기능과 유기적으로 연결된 구조**로 작동합니다.  
예를 들어, 사용자의 질문이 들어오면 n8n 워크플로우가 작동하여  
의도를 분석하고, 필요한 데이터를 서버에서 직접 조회해 응답을 생성합니다.  

---

## ⚙️ N8N? 🤔

![작성 워크플로우](https://github.com/user-attachments/assets/d26cfe96-38d0-4952-aed9-6b503e55ac9a)

**n8n**은 오픈소스 자동화 툴로, 다양한 서비스 간의 연결과  
데이터 흐름을 **시각적 워크플로우**로 구성할 수 있는 플랫폼입니다.  
우리 시스템에서는 **AI 기반 의도 분석, 데이터 처리, 서버 통신**을 모두 n8n에서 자동화했습니다.  

n8n을 활용한 이유는 다음과 같습니다:
- LLM 요청 및 데이터 응답 흐름을 **시각적으로 관리 가능**
- 조건 분기(Switch), HTTP 요청, 함수 실행 등 **세밀한 제어 가능**
- 서버와 AI 에이전트 간 통신을 단일 파이프라인으로 **표준화**

<img width="981" height="773" alt="n8n-workflow" src="https://github.com/user-attachments/assets/636797df-1fd1-49c4-975a-7b75f7c1e4f6" />


---

## 🧩 챗봇 워크플로우 구조
<img width="964" height="564" alt="n8n" src="https://github.com/user-attachments/assets/e1264678-e968-4044-9723-cb48622d5587" />

n8n 내부에서 챗봇은 다음과 같은 흐름으로 동작합니다:

1. **사용자 요청 수신**  
   서버에서 n8n으로 요청이 들어오면 Webhook을 통해 워크플로우가 시작됩니다.
2. **의도 분석 (LLM)**  
   사용자의 자연어 요청을 분석해 “요약 요청인지”, “일정 조회인지” 등을 분류합니다.  
3. **분기 처리**  
   Switch 노드를 통해 각 의도에 맞는 LLM 또는 API 호출로 분기합니다.
4. **데이터 조회 및 응답 생성**  
   필요한 경우 서버 API를 호출하여 실시간 데이터를 가져오고,  
   LLM이 이를 요약하거나 정리해 최종 응답을 생성합니다.
5. **결과 반환**  
   생성된 결과는 다시 서버로 전송되어 사용자의 대화창에 표시됩니다.

이 구조를 통해 챗봇은 단순 응답을 넘어,  
**실시간 데이터 기반의 ‘지능형 업무 비서’ 역할**을 수행합니다.

---

## 🧠 Redis-Semantic: 의미 기반 캐싱 시스템
<img width="932" height="436" alt="시멘틱1" src="https://github.com/user-attachments/assets/e10884cd-590c-4497-81d7-9d50580229eb" />
<img width="1199" height="539" alt="시멘틱2" src="https://github.com/user-attachments/assets/467f9ded-c114-425c-b9da-83819451b4fb" />

챗봇의 지능형 응답을 가능하게 하는 또 하나의 핵심이 바로  
**Redis Stack 기반 시멘틱 메모리 구조**입니다.

### 작동 원리
1. 사용자의 질문을 OpenAI **임베딩 모델**로 변환 → 의미 벡터 생성  
2. 이 벡터를 **Redis Vector Space**에 저장  
3. 새로운 질문이 들어올 때마다 기존 벡터들과 **유사도 검색 (KNN)** 수행  
4. **90% 이상 유사한 벡터**가 존재하면 LLM 호출 없이 **저장된 응답 즉시 반환**  
5. 유사도가 낮을 경우 LLM을 호출하고, 새 결과를 Redis에 다시 저장

### 효과
- **응답 속도 향상:** 유사 질의는 캐시된 응답을 즉시 반환  
- **비용 절감:** OpenAI API 호출 횟수를 대폭 감소  
- **지속 학습:** Redis가 점차 “지식 저장소”로 확장  

---

## 💡 요약

| 구성 요소 | 역할 | 특징 |
|------------|------|------|
| **N8N Agent** | 챗봇 의도 분석 및 응답 생성 자동화 | LLM 기반 분기 처리 |
| **Redis-Semantic** | 의미 기반 질의 캐싱 | 유사 질문 즉시 응답 |
| **LLM 모듈** | 요약 / 일정 / 채팅 / 일반 응답 처리 | OpenAI 모델 연동 |
| **서버 연동** | 데이터 조회 및 결과 반환 | REST API 통신 |

---

## 🚀 결론

이 구조를 통해 챗봇은 단순 대화형 UI를 넘어,  
**AI와 데이터가 유기적으로 통합된 스마트 업무 파이프라인**으로 진화했습니다.  
n8n의 자동화와 Redis-Semantic의 의미 기반 캐싱을 결합함으로써  
빠르고 정확하며 비용 효율적인 지능형 챗봇을 완성할 수 있었습니다.

---

  </div>
</details>




